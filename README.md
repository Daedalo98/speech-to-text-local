Hereâ€™s a polished **README.md** for your repo speechâ€‘toâ€‘textâ€‘local â€” you can copy and paste it into your GitHub project, then tweak any text you want. Ooooh, here it is:

# Speechâ€‘toâ€‘Text Local (offline, realtime)  
**Fully local realtime speechâ€‘toâ€‘text GUI using Vosk**  

## ğŸš€ What it is  
This project provides a minimalâ€‘GUI Python app that captures microphone audio and converts it to text **entirely offline**, using the Vosk speech recognition engine.  
Youâ€™ll see *partial text updates* in real time and *final transcriptions* accumulated in a window.  
Perfect for privacyâ€‘savvy, fast local transcription without cloud services.

## âœ… Key features  
- Offline speechâ€‘toâ€‘text â€” no internet required once model is downloaded  
- Realâ€‘time display of partial and final text results  
- Simple Tkinter GUI: Start / Stop / Clear / Copy All  
- Suitable for single speaker or multiâ€‘speaker (with manual color tagging, configurable)  
- Easy to configure, crossâ€‘platform (Linux/macOS/Windows)  
- Intended for live transcription, noteâ€‘taking, accessibility, podcasts, etc.

## ğŸ› ï¸ Setup & quick start  

### Prerequisites  
- Python **3.9+**, recommended 3.11 or 3.12  
- Microphone access and working audio input  
- On **Linux**: ensure `libportaudio2` (or equivalent) is installed; `python3â€‘tk` (for Tkinter)  
- On **macOS/Windows**: mic access permissions, Python distribution from python.org recommended

### Installation & first run  
From your project root:

```bash
./scripts/run.sh --device N
````

Where `N` is the device index of your microphone.
(E.g., `--device 0` for default; you can run `python -c "import sounddevice as sd; print(sd.query_devices())"` to list devices.)

The `run.sh` script will:

1. Create/activate a virtual environment (`.venv`)
2. Install required dependencies (`requirements.txt`)
3. Download the default Italian Vosk model (if not already present)
4. Launch the GUI

### Manual installation steps

If you prefer manual control:

```bash
python3 -m venv .venv
source .venv/bin/activate          # Windows: .venv\Scripts\activate
pip install -r requirements.txt
./scripts/download_model.sh
python3 src/app.py --device N
```

## ğŸ“ Directory structure

```
speechâ€‘toâ€‘textâ€‘local/
â”œâ”€ src/
â”‚  â”œâ”€ app.py            # entryâ€‘point GUI & CLI
â”‚  â”œâ”€ gui.py            # Tkinter user interface
â”‚  â”œâ”€ audio_stream.py   # microphone stream capture
â”‚  â”œâ”€ stt_vosk.py       # Vosk recognizer wrapper
â”‚  â””â”€ utils.py          # utility functions (paths, logging, config)
â”œâ”€ models/
â”‚  â””â”€ it/
â”‚      â””â”€ model/        # downloaded Vosk Italian model files here
â”œâ”€ scripts/
â”‚  â”œâ”€ setup.sh          # setup venv, install deps, download model
â”‚  â”œâ”€ download_model.sh # download/prepare Vosk model
â”‚  â””â”€ run.sh            # full â€œsetup + runâ€ script
â”œâ”€ tests/               # placeholder test files
â”œâ”€ assets/              # (optional) UI icons or other resources
â”œâ”€ README.md
â”œâ”€ requirements.txt
â”œâ”€ pyproject.toml
â””â”€ LICENSE
```

## ğŸ¨ Customisation & enhancements

Feel free to tweak/add:

* **Different colours for different voices/speakers** (via `tk.Text` tags)
* **Copy All / Export to .txt** functionality (button already present)
* **Pauseâ€‘based segmentation**: long silences trigger paragraph breaks
* Model for other languages: swap URL in `download_model.sh`, set `STT_MODEL_DIR` env var
* Adjust sample rate, channels, block size in `audio_stream.py` for latency tuning

## ğŸ§° Troubleshooting & Tips

* If you see: `Error querying device -1` â†’ run `python -c "import sounddevice as sd; print(sd.query_devices())"` and pick a valid device index, then use `--device N`.
* If you get â€œmodel not foundâ€ â†’ verify that `models/it/model/vosk-model.conf` exists. Move model files correctly if needed.
* For Linux: if microphone shows no input, check `arecord -l`, `pavucontrol`, and ensure PortAudio is working.
* In case of high latency: reduce `blocksize` or increase sample rate; or use a faster/slimmer model.

## ğŸ“„ License

This project is licensed under the [MIT License](./LICENSE) â€” use and modify it freely.

## ğŸ¤ Contributions & Feedback

Feel free to open issues, suggest features, or submit pull requests.
Would love to hear your feedback on accuracy, latency, and usability.

---

*Created with â¤ï¸ by Daedalo98*

